{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225 - 2225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dokumen</th>\n",
       "      <th>Tokenisasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>[Ad, sales, boost, Time, Warner, profit, Quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>[Dollar, gains, on, Greenspan, speech, The, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>[Yukos, unit, buyer, faces, loan, claim, The, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>[High, fuel, prices, hit, BAs, profits, Britis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>[Pernod, takeover, talk, lifts, Domecq, Shares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams</td>\n",
       "      <td>[BT, program, to, beat, dialler, scams, BT, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers</td>\n",
       "      <td>[Spam, emails, tempt, net, shoppers, Computer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code</td>\n",
       "      <td>[Be, careful, how, you, code, A, new, European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns</td>\n",
       "      <td>[US, cyber, security, chief, resigns, The, man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>[Losing, yourself, in, online, gaming, Online,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Dokumen  \\\n",
       "0     Ad sales boost Time Warner profit   \n",
       "1      Dollar gains on Greenspan speech   \n",
       "2     Yukos unit buyer faces loan claim   \n",
       "3     High fuel prices hit BA's profits   \n",
       "4     Pernod takeover talk lifts Domecq   \n",
       "...                                 ...   \n",
       "2220   BT program to beat dialler scams   \n",
       "2221    Spam e-mails tempt net shoppers   \n",
       "2222            Be careful how you code   \n",
       "2223    US cyber security chief resigns   \n",
       "2224   Losing yourself in online gaming   \n",
       "\n",
       "                                             Tokenisasi  \n",
       "0     [Ad, sales, boost, Time, Warner, profit, Quart...  \n",
       "1     [Dollar, gains, on, Greenspan, speech, The, do...  \n",
       "2     [Yukos, unit, buyer, faces, loan, claim, The, ...  \n",
       "3     [High, fuel, prices, hit, BAs, profits, Britis...  \n",
       "4     [Pernod, takeover, talk, lifts, Domecq, Shares...  \n",
       "...                                                 ...  \n",
       "2220  [BT, program, to, beat, dialler, scams, BT, is...  \n",
       "2221  [Spam, emails, tempt, net, shoppers, Computer,...  \n",
       "2222  [Be, careful, how, you, code, A, new, European...  \n",
       "2223  [US, cyber, security, chief, resigns, The, man...  \n",
       "2224  [Losing, yourself, in, online, gaming, Online,...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('bbc_text_cls new.csv')\n",
    "\n",
    "limit = len(df)  # Misalkan kita ingin mengambil 5 baris pertama\n",
    "\n",
    "dfTokenization = pd.DataFrame(columns=['Dokumen','Tokenisasi'])\n",
    "dfTokenization\n",
    "\n",
    "def tokenize_string(input_string):\n",
    "    # Menghapus simbol dan hanya menyisakan huruf dan angka\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', input_string)\n",
    "    \n",
    "    # Memecah string menjadi token (kata) berdasarkan spasi\n",
    "    tokens = cleaned_string.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Membaca baris dan kolom tertentu (misal kolom pertama 'Nama')\n",
    "hasil = \"\"\n",
    "judulDok = \"\"\n",
    "isiText = \"\"\n",
    "for index in range(min(limit, len(df))):  # Menggunakan min untuk menghindari index out of range\n",
    "    judulDok = str(df.iloc[index, 0])# Mengambil kolom pertama (indeks 0)\n",
    "    isiText = judulDok\n",
    "    splittedBaris = judulDok.split('\\n')\n",
    "    dfTokenization.loc[len(dfTokenization)] = [splittedBaris[0], tokenize_string(isiText)]\n",
    "\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"{len(dfTokenization)} - {len(df)}\")\n",
    "dfTokenization.to_csv('hasil_tokenisasi.csv')\n",
    "dfTokenization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
